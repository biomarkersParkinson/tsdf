{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "These are some examples on how to read and write TSDF data into and from a numpy array."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run these examples\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "In order to run these examples, we'll need to use the following Python packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tsdf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test  files\n",
    "\n",
    "The test files used in these examples can be found in [`../tests/data/`](https://github.com/biomarkersParkinson/tsdf/tree/main/tests/data). Use the snippet below to locate your copy of the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTDATA_DIR = os.path.join(\"..\", \"tests\", \"data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc\n",
    "\n",
    "Last and thus least, the following lines may be useful for developing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules automatically on changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process an existing binary file and write the new TSDF metadata\n",
    "Read and process an existing binary data (accompanied by the TSDF metadata), process the data and save it in the new format, with the corresponding TSDF metadata file.\n",
    "\n",
    "### Load dummy data and see its format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type used for storing:\t int16\n",
      "Data dimensions:\t\t (10, 3)\n",
      "Number of rows:\t\t\t 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dummy_data_name = \"dummy_10_3_int16\"\n",
    "\n",
    "dummy_metadata = tsdf.load_metadata_from_path(os.path.join(TESTDATA_DIR, dummy_data_name + \".json\"))[dummy_data_name + \".bin\"]\n",
    "dummy_data = dummy_metadata.load_binary()\n",
    "print(f\"Data type used for storing:\\t {dummy_data.dtype}\")\n",
    "print(f\"Data dimensions:\\t\\t {dummy_data.shape}\")\n",
    "print(f\"Number of rows:\\t\\t\\t {dummy_data.shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform light data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type used for storing:\t float32\n",
      "Data dimensions:\t\t (10, 3)\n",
      "Number of rows:\t\t\t 10\n"
     ]
    }
   ],
   "source": [
    "processed_dummy_data_1 = (dummy_data / 10).astype('float32')\n",
    "print(f\"Data type used for storing:\\t {processed_dummy_data_1.dtype}\")\n",
    "print(f\"Data dimensions:\\t\\t {processed_dummy_data_1.shape}\")\n",
    "print(f\"Number of rows:\\t\\t\\t {processed_dummy_data_1.shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata available from the data (NumPy array)\n",
    "The metadata will be used indirectly to generate the new TSDF metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary formatting that can be inferred from the NumPy array:\n",
      "{'data_type': 'float', 'bits': 32, 'endianness': 'little', 'rows': 10}\n"
     ]
    }
   ],
   "source": [
    "bin_meta = tsdf.get_metadata_from_ndarray(processed_dummy_data_1)\n",
    "print(f\"Binary formatting that can be inferred from the NumPy array:\\n{bin_meta}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the processed data \n",
    "Write the processed data in binary format. The call returns the corresponding metadata object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dummy_data_name_1 = \"tmp_test_dummy_10_3_int16_to_float32\"\n",
    "processed_dummy_metadata_1 = tsdf.write_binary_file(\n",
    "            TESTDATA_DIR,\n",
    "            processed_dummy_data_name_1 + \".bin\",\n",
    "            processed_dummy_data_1,\n",
    "            dummy_metadata.get_plain_tsdf_dict_copy(),\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the TSDF metadata file that describes the processed binary data format\n",
    "\n",
    "#### 1) Write the metadata file for a single binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write new metadata file\n",
    "tsdf.write_metadata([processed_dummy_metadata_1], processed_dummy_data_name_1 + \".json\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Write a metadata file that combines multiple binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the original data to generate another data source\n",
    "processed_dummy_data_2 = (dummy_data * 1000).astype('int32')\n",
    "\n",
    "# Adjust the metadata slightly\n",
    "updated_dummy_metadata = dummy_metadata.get_plain_tsdf_dict_copy()\n",
    "updated_dummy_metadata.pop(\"scale_factors\") #remove the 'scale_factors'\n",
    "\n",
    "\n",
    "# Save the new binary file\n",
    "processed_dummy_data_name_2 = \"tmp_test_dummy_10_3_int16_to_int32\"\n",
    "processed_dummy_metadata_2 = tsdf.write_binary_file(\n",
    "            TESTDATA_DIR,\n",
    "            processed_dummy_data_name_2 + \".bin\",\n",
    "            processed_dummy_data_2,\n",
    "            updated_dummy_metadata,\n",
    "        )\n",
    "\n",
    "# Write a metadata file that combines the two binary files\n",
    "tsdf.write_metadata([processed_dummy_metadata_1, processed_dummy_metadata_2], \"tmp_test_dummy_10_3_int16_to_int_n_float.json\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genarate a new binary file and the corresponding TSDF metadata\n",
    "Generate binary data and save it and the corresponding TSDF metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(TESTDATA_DIR, \"test_output_1.bin\")\n",
    "rs = np.random.RandomState(seed=42)\n",
    "data_1 = rs.rand(17, 1).astype(np.float32)\n",
    "data_2 = rs.rand(15, 2).astype(np.int16)\n",
    "data_3 = rs.rand(10, 3).astype(np.int16)\n",
    "\n",
    "\n",
    "# An example where the metadata is defined from scratch\n",
    "new_metadata = {}\n",
    "new_metadata[\"subject_id\"] = \"example\"\n",
    "new_metadata[\"study_id\"] = \"example\"\n",
    "new_metadata[\"device_id\"] = \"example\"\n",
    "new_metadata[\"endianness\"] = \"little\"\n",
    "new_metadata[\"metadata_version\"] = \"0.1\"\n",
    "new_metadata[\"start_datetime_unix_ms\"] = 1571135957025,\n",
    "new_metadata[\"start_iso8601\"] = \"2019-10-15T10:39:17.025000+00:00\"\n",
    "new_metadata[\"end_datetime_unix_ms\"] = 1571168851826\n",
    "new_metadata[\"end_iso8601\"] = \"2019-10-15T19:47:31.826000+00:00\"\n",
    "new_metadata[\"channels\"] = [\"x\",\"y\",\"z\"]\n",
    "new_metadata[\"units\"] = [\"m/s/s\",\"m/s/s\",\"m/s/s\"]\n",
    "\n",
    "# Write the three binary files based on the provided metadata\n",
    "\n",
    "file_prefix = \"tmp_test\"\n",
    "new_meta_1 =  tsdf.write_binary_file(TESTDATA_DIR, file_prefix + \"_1.bin\", data_1, new_metadata)\n",
    "new_meta_2 =  tsdf.write_binary_file(TESTDATA_DIR, file_prefix+\"_2.bin\", data_2, new_metadata)\n",
    "new_meta_3 =  tsdf.write_binary_file(TESTDATA_DIR, file_prefix+\"_3.bin\", data_3, new_metadata)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the metadata that corresponds to the binary data. In case of multiple binary files, the corresponding metadata files have to be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the first metadata file\n",
    "tsdf.write_metadata([new_meta_1], file_prefix +\"_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and write all metadata files\n",
    "tsdf.write_metadata([new_meta_1, new_meta_2, new_meta_3], file_prefix+\"_3.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsdf-zVA6tG---py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1e978847a77d4ff49203fd09f0f7925f58560bf1007438482d75cb657018d9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
