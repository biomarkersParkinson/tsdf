{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Very rough adaptation of Jordan's original python example. Extracts a generic function to read the binary data.\n",
    "\n",
    "@author: Jordan Raykov\n",
    "This code replicates the MATLAB example_view_ppp_imu.m and all of the dependent functions. \n",
    "The script loads IMU (gyro and accelerometer) sensor data, as well as, json meta-data which is stored in jsonobj  \n",
    "\"\"\"\n",
    "\n",
    "import os \n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_mapping = {\n",
    "    'float': 'f',\n",
    "    'int': 'i'\n",
    "}\n",
    "\n",
    "def read_binary_file(file_path, type, nbits, endianness, ncolumns):\n",
    "    s_endianness = '<' if endianness == 'little' else '>'\n",
    "    s_type = dtype_mapping[type]\n",
    "    s_nbytes = str(nbits // 8)\n",
    "    format_string = ''.join([s_endianness, s_type, s_nbytes])\n",
    "\n",
    "    with open(file_path, 'rb') as fid:\n",
    "        values = np.fromfile(fid, dtype=format_string)\n",
    "        if ncolumns > 1:\n",
    "            values = values.reshape((-1, ncolumns))\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsdb load function uses metafilename as input to locate the corresponding \n",
    "# path of a json file and sensor data file from specified file_name \n",
    "def tsdb_load(metafilename):\n",
    "    pathstr = os.path.dirname(os.path.abspath(metafilename))\n",
    "    # Opening JSON file\n",
    "    f = open(metafilename)\n",
    "    # returns JSON object as a dictionary\n",
    "    jsonobj = json.load(f)\n",
    "    N = len(jsonobj['datasets'])\n",
    "    unix_ticks_ms = 1000.0;    \n",
    "    values_list = []    \n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    start_time_unix = []\n",
    "    end_time_unix = []\n",
    "    startsecs = []\n",
    "    endsecs = []\n",
    "    device_id = []\n",
    "    project_id = []\n",
    "    startdatenum = []\n",
    "    enddatenum = []\n",
    "    filename = []\n",
    "    quantity = []\n",
    "    units = []\n",
    "    scale_factors = []\n",
    "    bits = []\n",
    "    datatype = []\n",
    "    rows = []\n",
    "    cols = []\n",
    "\n",
    "    for n in range(N):\n",
    "        ds = jsonobj['datasets'][n]\n",
    "        start_time_unix.append(float(jsonobj['start_datetime_unix_ms']))\n",
    "        end_time_unix.append(jsonobj['end_datetime_unix_ms'])\n",
    "        startsecs = jsonobj['start_datetime_unix_ms']/unix_ticks_ms\n",
    "        endsecs   = jsonobj['end_datetime_unix_ms']/unix_ticks_ms\n",
    "        device_id.append(jsonobj['device_id'])\n",
    "        project_id.append(jsonobj['project_id'])\n",
    "    \n",
    "        filename.append(ds['file_name'])\n",
    "        quantity.append(ds['quantities'])\n",
    "        units.append(ds['units'])\n",
    "        scale_factors.append(ds['scale_factors'])\n",
    "        bits.append(ds['bits'])\n",
    "        datatype.append(ds['datatype'])\n",
    "        rows.append(ds['rows'])\n",
    "        cols.append(ds['columns'])\n",
    "\n",
    "    \n",
    "        filenamestr = os.path.join(pathstr, ds['file_name'])\n",
    "        values = read_binary_file(filenamestr, ds['datatype'], ds['bits'], jsonobj['endianness'], ds['columns'])\n",
    "        print(values.shape)\n",
    "        \n",
    "        values_list.append(values)\n",
    "    data['start_time_unix_ms'] = start_time_unix\n",
    "    data['end_time_unix_ms'] = end_time_unix\n",
    "    data['startsecs'] = startsecs\n",
    "    data['endsecs'] = endsecs\n",
    "    data['device_id'] = device_id\n",
    "    data['project_id'] = project_id\n",
    "    data['filename'] = filename\n",
    "    data['quantities'] = quantity\n",
    "    data['units'] = units\n",
    "    data['scale_factors'] = scale_factors\n",
    "    data['bits'] = bits\n",
    "    data['datatype'] = datatype\n",
    "    data['rows'] = rows\n",
    "    data['columns'] = cols\n",
    "    \n",
    "    return data, values_list, jsonobj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect meta data file names\n",
    "\n",
    "ppp_data_path = '../../data/PPP_IMU_wk10_000077_tsdf';\n",
    "\n",
    "# Example of loading and plotting all IMU data for a particular user\n",
    "#ppp_pep_userid = 'FCCE5BD27F7C2F7260169F99B1144FC53CBB8120799A3230FDCC9A68CB549C50'\n",
    "\n",
    "unix_ticks_ms = 1000.0\n",
    "\n",
    "# Load each segment's TSDB file in turn, dumping values and time indices\n",
    "# into a local copy for plotting\n",
    "\n",
    "meta_segments_list = glob.glob(os.path.join(ppp_data_path, 'WatchData.IMU.Week10.raw_segment*_meta.json'))\n",
    "\n",
    "meta_filenames = []\n",
    "for name in meta_segments_list:\n",
    "    meta_filenames.append(os.path.basename(name))\n",
    "    \n",
    "Nfiles = len(meta_filenames)\n",
    "print(meta_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.byteorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "v = []\n",
    "\n",
    "ts = np.zeros((Nfiles, 2))\n",
    "for n in range(Nfiles):\n",
    "    meta_fullpath = os.path.join(ppp_data_path, meta_filenames[n])\n",
    "    data, data_values, jsonobj = tsdb_load(meta_fullpath)\n",
    "    ts[n] = data['start_time_unix_ms']\n",
    "    t.append(np.cumsum(np.double(data_values[0])) + ts[n,0])\n",
    "    v.append(data_values[1])\n",
    "    del data # For memory conservation, don't keep original data hanging around\n",
    "    del data_values\n",
    "\n",
    "fig, axs = plt.subplots(Nfiles)\n",
    "for n in range(Nfiles):\n",
    "    tr = (t[n]-ts[n,0])/unix_ticks_ms\n",
    "    axs[n].plot(tr, v[n]) \n",
    "    plt.xlabel('Elapsed time (s)')\n",
    "    plt.ylabel('IMU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.dtype('>f4')\n",
    "print(dt, dt.byteorder, dt.itemsize, dt.descr, dt.kind)\n",
    "dt = np.dtype('float32')\n",
    "print(dt, dt.byteorder, dt.itemsize, dt.descr, dt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsdb load function uses metafilename as input to locate the corresponding \n",
    "# path of a json file and sensor data file from specified file_name \n",
    "def tsdb_load_old(metafilename):\n",
    "    pathstr = os.path.dirname(os.path.abspath(metafilename))\n",
    "    # Opening JSON file\n",
    "    f = open(metafilename)\n",
    "    # returns JSON object as a dictionary\n",
    "    jsonobj = json.load(f)\n",
    "    N = len(jsonobj['datasets'])\n",
    "    unix_ticks_ms = 1000.0;    \n",
    "    values_list = []    \n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    start_time_unix = []\n",
    "    end_time_unix = []\n",
    "    startsecs = []\n",
    "    endsecs = []\n",
    "    device_id = []\n",
    "    project_id = []\n",
    "    startdatenum = []\n",
    "    enddatenum = []\n",
    "    filename = []\n",
    "    quantity = []\n",
    "    units = []\n",
    "    scale_factors = []\n",
    "    bits = []\n",
    "    datatype = []\n",
    "    rows = []\n",
    "    cols = []\n",
    "\n",
    "    for n in range(N):\n",
    "        ds = jsonobj['datasets'][n]\n",
    "        start_time_unix.append(float(jsonobj['start_datetime_unix_ms']))\n",
    "        end_time_unix.append(jsonobj['end_datetime_unix_ms'])\n",
    "        startsecs = jsonobj['start_datetime_unix_ms']/unix_ticks_ms\n",
    "        endsecs   = jsonobj['end_datetime_unix_ms']/unix_ticks_ms\n",
    "        device_id.append(jsonobj['device_id'])\n",
    "        project_id.append(jsonobj['project_id'])\n",
    "    \n",
    "        filename.append(ds['file_name'])\n",
    "        quantity.append(ds['quantities'])\n",
    "        units.append(ds['units'])\n",
    "        scale_factors.append(ds['scale_factors'])\n",
    "        bits.append(ds['bits'])\n",
    "        datatype.append(ds['datatype'])\n",
    "        rows.append(ds['rows'])\n",
    "        cols.append(ds['columns'])\n",
    "\n",
    "    \n",
    "        filenamestr = os.path.join(pathstr, ds['file_name'])\n",
    "        # Prepare data type string for binary fread\n",
    "        if ds['datatype']  == 'double':\n",
    "            format_var = 'float'+str(ds['bits'])\n",
    "        else:\n",
    "            format_var = ds['datatype'] + str(ds['bits'])\n",
    "            \n",
    "        #  Decipher byteorder\n",
    "        if jsonobj['endianness'] == 'little':\n",
    "            byteorder = '<f4'\n",
    "        else:\n",
    "            byteorder = '>f8'\n",
    "       \n",
    "        # specify format of the loaded variables, either [Inf 6] for IMU \n",
    "        # sensor data or [Inf 1] for timestamp array\n",
    "        if n == 0: \n",
    "            with open(filenamestr, 'rb') as fid:\n",
    "                values = np.fromfile(fid, dtype=format_var)\n",
    "        elif n == 1:\n",
    "            with open(filenamestr, 'rb') as fid:\n",
    "                values = np.fromfile(fid, dtype=format_var).reshape((-1, 6))\n",
    "        if len(values)>0:\n",
    "            values.T\n",
    "\n",
    "        print(values.shape)\n",
    "\n",
    "        values_list.append(values)\n",
    "    data['start_time_unix_ms'] = start_time_unix\n",
    "    data['end_time_unix_ms'] = end_time_unix\n",
    "    data['startsecs'] = startsecs\n",
    "    data['endsecs'] = endsecs\n",
    "    data['device_id'] = device_id\n",
    "    data['project_id'] = project_id\n",
    "    data['filename'] = filename\n",
    "    data['quantities'] = quantity\n",
    "    data['units'] = units\n",
    "    data['scale_factors'] = scale_factors\n",
    "    data['bits'] = bits\n",
    "    data['datatype'] = datatype\n",
    "    data['rows'] = rows\n",
    "    data['columns'] = cols\n",
    "    \n",
    "    return data, values_list, jsonobj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0ab77bcfd285eeaac2f5e895261c5cbe96f15cb3eb6b9e858040163096b370e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
